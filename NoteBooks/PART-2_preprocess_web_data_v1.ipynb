{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1b4kco862abMBn8j5PEdAWKMgLBydWEGF","timestamp":1704562577409},{"file_id":"1vqp38x5aWySx5FrEC_JbzHbA3kUK6-ZK","timestamp":1703961883733},{"file_id":"1DtDZ-FBxcNSbZAxbiAE3A3gfTx9We9ki","timestamp":1703872868379}],"authorship_tag":"ABX9TyOy8fYXYSjdkZU8jOB4l4YL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# PRE-PROCESS WEBSCRAPED DATA\n","\n","----------------------------\n","#### GIST OF CHANGES DONE IN THIS NOTEBOOK\n","----------------------------\n","-   This code handles basic data cleansing like handing or dropping nulls, replace special characters etc\n","-   The initial webscraped data contains multiples examples and descriptions in the code snippet. These were extracted and new rows were created for each of these examples.\n","-    All undesired rows in the code examples like code output etc were ignored.\n","-    The code snippets were limited to only single line codes and all other noise like comments or unwanted code were removed from the code snippets. This is because one objective of the target model is to predict only modular or component level code and not anything else.\n","-    Import statements if applicable were moved into another column. These are the only lines of code which will be eventually merged to the single line codes derived in the previous step. This merge will be done later prior to training.\n","-    The html separator '\\<br\\>' is used in the code currently as it aids in displaying the newlines within the code while displaying collab dataset results. This will be replaced later with '\\n' prior to training.\n","----------------------------\n","<br>\n","<br>\n"],"metadata":{"id":"jdYDazNza3x0"}},{"cell_type":"code","source":["# IMPORT NECESSARY PACKAGES\n","import io\n","import pandas as pd\n","from google.colab import drive\n"],"metadata":{"id":"OfPB61Gz8VfY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DISPLAY FUNCTIONS\n","def fn_display_header(msg):\n","  print('-' * 80)\n","  print(' ' * 10, msg)\n","  print('-' * 80)\n","\n","def fn_display_message(msg):\n","  print(msg)"],"metadata":{"id":"pEiTi6z_8rTF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# READ WEB SCRAPED DATA INTO DATAFRAME AND DISPLAY DETAILS\n","\n","df_raw = pd.read_csv('ETL_P1_get_raw_web_data_v1.csv').drop('Unnamed: 0', axis=1)\n","\n","fn_display_header('Display Dataframe Metadata')\n","df_raw.info()\n","\n","fn_display_header('Display initial Web Scraped Dataframe')\n","df_raw.head(10)#.style.set_properties(**{'text-align': 'left'})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":675},"id":"AJTTKnDD3UA8","executionInfo":{"status":"ok","timestamp":1709782100538,"user_tz":-330,"elapsed":30,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"bf14ef18-9684-46cb-bfd1-f42f3089aa1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","           Display Dataframe Metadata\n","--------------------------------------------------------------------------------\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 740 entries, 0 to 739\n","Data columns (total 5 columns):\n"," #   Column        Non-Null Count  Dtype \n","---  ------        --------------  ----- \n"," 0   Category      740 non-null    object\n"," 1   function      740 non-null    object\n"," 2   feature_desc  730 non-null    object\n"," 3   example_text  740 non-null    object\n"," 4   link          740 non-null    object\n","dtypes: object(5)\n","memory usage: 29.0+ KB\n","--------------------------------------------------------------------------------\n","           Display initial Web Scraped Dataframe\n","--------------------------------------------------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["        Category                             function  \\\n","0  Configuration       pyspark.sql.conf.RuntimeConfig   \n","1   Input/Output      pyspark.sql.DataFrameReader.csv   \n","2   Input/Output   pyspark.sql.DataFrameReader.format   \n","3   Input/Output     pyspark.sql.DataFrameReader.jdbc   \n","4   Input/Output     pyspark.sql.DataFrameReader.json   \n","5   Input/Output     pyspark.sql.DataFrameReader.load   \n","6   Input/Output   pyspark.sql.DataFrameReader.option   \n","7   Input/Output  pyspark.sql.DataFrameReader.options   \n","8   Input/Output      pyspark.sql.DataFrameReader.orc   \n","9   Input/Output  pyspark.sql.DataFrameReader.parquet   \n","\n","                                        feature_desc  \\\n","0  User facing configuration API  accessible thro...   \n","1  Loads a CSV file and returns the result as a  ...   \n","2            Specifies the input data source format.   \n","3  Construct a DataFrame representing the databas...   \n","4  Loads JSON files and returns the results as a ...   \n","5  Loads data from a data source and returns it a...   \n","6  Adds an input option for the underlying data s...   \n","7  Adds input options for the underlying data sou...   \n","8  Loads ORC files  returning the result as a Dat...   \n","9  Loads Parquet files  returning the result as a...   \n","\n","                                        example_text  \\\n","0   # User-facing configuration API, accessible t...   \n","1   # Write a DataFrame into a CSV file and read ...   \n","2  <br>>>> spark.read.format('json')<br><...readw...   \n","3   # Construct a DataFrame representing the data...   \n","4   # Write a DataFrame into a JSON file and read...   \n","5   # Load a CSV file with format, schema and opt...   \n","6  <br>>>> spark.read.option(\"key\", \"value\")<br><...   \n","7  <br>>>> spark.read.option(\"key\", \"value\")<br><...   \n","8   # Write a DataFrame into a ORC file and read ...   \n","9   # Write a DataFrame into a Parquet file and r...   \n","\n","                                                link  \n","0  https://spark.apache.org/docs/latest/api/pytho...  \n","1  https://spark.apache.org/docs/latest/api/pytho...  \n","2  https://spark.apache.org/docs/latest/api/pytho...  \n","3  https://spark.apache.org/docs/latest/api/pytho...  \n","4  https://spark.apache.org/docs/latest/api/pytho...  \n","5  https://spark.apache.org/docs/latest/api/pytho...  \n","6  https://spark.apache.org/docs/latest/api/pytho...  \n","7  https://spark.apache.org/docs/latest/api/pytho...  \n","8  https://spark.apache.org/docs/latest/api/pytho...  \n","9  https://spark.apache.org/docs/latest/api/pytho...  "],"text/html":["\n","  <div id=\"df-966db95e-a080-4f37-b2ac-288b082141d4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>function</th>\n","      <th>feature_desc</th>\n","      <th>example_text</th>\n","      <th>link</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Configuration</td>\n","      <td>pyspark.sql.conf.RuntimeConfig</td>\n","      <td>User facing configuration API  accessible thro...</td>\n","      <td># User-facing configuration API, accessible t...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","      <td>Loads a CSV file and returns the result as a  ...</td>\n","      <td># Write a DataFrame into a CSV file and read ...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.format</td>\n","      <td>Specifies the input data source format.</td>\n","      <td>&lt;br&gt;&gt;&gt;&gt; spark.read.format('json')&lt;br&gt;&lt;...readw...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.jdbc</td>\n","      <td>Construct a DataFrame representing the databas...</td>\n","      <td># Construct a DataFrame representing the data...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.json</td>\n","      <td>Loads JSON files and returns the results as a ...</td>\n","      <td># Write a DataFrame into a JSON file and read...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.load</td>\n","      <td>Loads data from a data source and returns it a...</td>\n","      <td># Load a CSV file with format, schema and opt...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.option</td>\n","      <td>Adds an input option for the underlying data s...</td>\n","      <td>&lt;br&gt;&gt;&gt;&gt; spark.read.option(\"key\", \"value\")&lt;br&gt;&lt;...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.options</td>\n","      <td>Adds input options for the underlying data sou...</td>\n","      <td>&lt;br&gt;&gt;&gt;&gt; spark.read.option(\"key\", \"value\")&lt;br&gt;&lt;...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.orc</td>\n","      <td>Loads ORC files  returning the result as a Dat...</td>\n","      <td># Write a DataFrame into a ORC file and read ...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.parquet</td>\n","      <td>Loads Parquet files  returning the result as a...</td>\n","      <td># Write a DataFrame into a Parquet file and r...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-966db95e-a080-4f37-b2ac-288b082141d4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-966db95e-a080-4f37-b2ac-288b082141d4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-966db95e-a080-4f37-b2ac-288b082141d4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-51cf656e-67db-4867-b5f7-a7717a3d5c11\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51cf656e-67db-4867-b5f7-a7717a3d5c11')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-51cf656e-67db-4867-b5f7-a7717a3d5c11 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_raw","summary":"{\n  \"name\": \"df_raw\",\n  \"rows\": 740,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"Collection Functions\",\n          \"UDF\",\n          \"Datetime Functions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"function\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 703,\n        \"samples\": [\n          \"pyspark.sql.functions.stddev_samp\",\n          \"pyspark.sql.Column.bitwiseXOR\",\n          \"pyspark.sql.DataFrame.createGlobalTempView\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_desc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 638,\n        \"samples\": [\n          \"Computes tangent of the input column.\",\n          \"Computes cosine of the input column.\",\n          \"Add write options.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"example_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 679,\n        \"samples\": [\n          \"<br>>>> spark.catalog.currentDatabase()<br>'default'<br> \",\n          \"<br>>>> df = spark.createDataFrame([(\\\"2016-03-11 09:00:07\\\", 1)]).toDF(\\\"date\\\", \\\"val\\\")<br>>>> w = df.groupBy(session_window(\\\"date\\\", \\\"5 seconds\\\")).agg(sum(\\\"val\\\").alias(\\\"sum\\\"))<br>>>> w.select(w.session_window.start.cast(\\\"string\\\").alias(\\\"start\\\"),<br>...          w.session_window.end.cast(\\\"string\\\").alias(\\\"end\\\"), \\\"sum\\\").collect()<br>[Row(start='2016-03-11 09:00:07', end='2016-03-11 09:00:12', sum=1)]<br>>>> w = df.groupBy(session_window(\\\"date\\\", lit(\\\"5 seconds\\\"))).agg(sum(\\\"val\\\").alias(\\\"sum\\\"))<br>>>> w.select(w.session_window.start.cast(\\\"string\\\").alias(\\\"start\\\"),<br>...          w.session_window.end.cast(\\\"string\\\").alias(\\\"end\\\"), \\\"sum\\\").collect()<br>[Row(start='2016-03-11 09:00:07', end='2016-03-11 09:00:12', sum=1)]<br> \",\n          \"<br>>>> from pyspark.sql import Row<br>>>> from pyspark.sql.functions import col, lit<br>>>> df = spark.createDataFrame(<br>...     [(14, \\\"Tom\\\"), (23, \\\"Alice\\\"), (16, \\\"Bob\\\")], [\\\"age\\\", \\\"name\\\"])<br>>>> df2 = spark.createDataFrame([Row(height=80, name=\\\"Tom\\\"), Row(height=85, name=\\\"Bob\\\")])<br><br>>>> df.drop('age').show()<br>+-----+<br>| name|<br>+-----+<br>|  Tom|<br>|Alice|<br>|  Bob|<br>+-----+<br>>>> df.drop(df.age).show()<br>+-----+<br>| name|<br>+-----+<br>|  Tom|<br>|Alice|<br>|  Bob|<br>+-----+<br> # Drop the column that joined both DataFrames on.<br>>>> df.join(df2, df.name == df2.name, 'inner').drop('name').sort('age').show()<br>+---+------+<br>|age|height|<br>+---+------+<br>| 14|    80|<br>| 16|    85|<br>+---+------+<br><br>>>> df3 = df.join(df2)<br>>>> df3.show()<br>+---+-----+------+----+<br>|age| name|height|name|<br>+---+-----+------+----+<br>| 14|  Tom|    80| Tom|<br>| 14|  Tom|    85| Bob|<br>| 23|Alice|    80| Tom|<br>| 23|Alice|    85| Bob|<br>| 16|  Bob|    80| Tom|<br>| 16|  Bob|    85| Bob|<br>+---+-----+------+----+<br> # Drop two column by the same name.<br>>>> df3.drop(\\\"name\\\").show()<br>+---+------+<br>|age|height|<br>+---+------+<br>| 14|    80|<br>| 14|    85|<br>| 23|    80|<br>| 23|    85|<br>| 16|    80|<br>| 16|    85|<br>+---+------+<br> # Can not drop col(\\u00e2\\u0080\\u0098name\\u00e2\\u0080\\u0099) due to ambiguous reference.<br>>>> df3.drop(col(\\\"name\\\")).show()<br>Traceback (most recent call last):<br>...<br>pyspark.errors.exceptions.captured.AnalysisException: [AMBIGUOUS_REFERENCE] Reference...<br><br>>>> df4 = df.withColumn(\\\"a.b.c\\\", lit(1))<br>>>> df4.show()<br>+---+-----+-----+<br>|age| name|a.b.c|<br>+---+-----+-----+<br>| 14|  Tom|    1|<br>| 23|Alice|    1|<br>| 16|  Bob|    1|<br>+---+-----+-----+<br><br>>>> df4.drop(\\\"a.b.c\\\").show()<br>+---+-----+<br>|age| name|<br>+---+-----+<br>| 14|  Tom|<br>| 23|Alice|<br>| 16|  Bob|<br>+---+-----+<br> # Can not find a column matching the expression \\u00e2\\u0080\\u009ca.b.c\\u00e2\\u0080\\u009d.<br>>>> df4.drop(col(\\\"a.b.c\\\")).show()<br>+---+-----+-----+<br>|age| name|a.b.c|<br>+---+-----+-----+<br>| 14|  Tom|    1|<br>| 23|Alice|    1|<br>| 16|  Bob|    1|<br>+---+-----+-----+<br> \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 703,\n        \"samples\": [\n          \"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.stddev_samp.html#pyspark.sql.functions.stddev_samp\",\n          \"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.bitwiseXOR.html\",\n          \"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.createGlobalTempView.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# DISPLAY AND ANALYZE ROWS WITH NULL EXAMPLE_TEXT\n","\n","fn_display_header('Count of records with None or Null example_text')\n","fn_display_message('Null Count: ' + str(df_raw[df_raw['example_text'].isnull()].shape[0]))\n","\n","display_row_count = 10\n","fn_display_header('Display rows with None or Null example_text')\n","df_raw[df_raw['example_text'].isnull()].head(display_row_count)#.style.set_properties(**{'text-align': 'left'})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"oImTq3et5d_U","executionInfo":{"status":"ok","timestamp":1709782100538,"user_tz":-330,"elapsed":25,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"dedc24fd-b637-41d6-f921-699465bfc99a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","           Count of records with None or Null example_text\n","--------------------------------------------------------------------------------\n","Null Count: 0\n","--------------------------------------------------------------------------------\n","           Display rows with None or Null example_text\n","--------------------------------------------------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [Category, function, feature_desc, example_text, link]\n","Index: []"],"text/html":["\n","  <div id=\"df-a1df40b7-23a3-4793-8c7d-8035653637be\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>function</th>\n","      <th>feature_desc</th>\n","      <th>example_text</th>\n","      <th>link</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1df40b7-23a3-4793-8c7d-8035653637be')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a1df40b7-23a3-4793-8c7d-8035653637be button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a1df40b7-23a3-4793-8c7d-8035653637be');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"'str' object has no attribute 'empty'"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# REMOVE ALL ROWS WITH NULL VALUES OF EXAMPLE_TEXT\n","\n","fn_display_message(f' --> Initial Count : {df_raw.shape[0]}')\n","df_init = df_raw.dropna(subset=['example_text'])\n","fn_display_message(f' --> Count post dropping NULL exampe_text: {df_init.shape[0]}')\n","fn_display_header('Display Dataframe Metadata')\n","df_init.info()\n","\n","fn_display_header('Display Dataframe post removing rows with NULL example_text')\n","df_init.head(10)#.style.set_properties(**{'text-align': 'left'})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":710},"id":"yt6Nj_RL5eFB","executionInfo":{"status":"ok","timestamp":1709782100930,"user_tz":-330,"elapsed":413,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"a35495fc-af31-4f2f-f213-a706c7097942"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" --> Initial Count : 740\n"," --> Count post dropping NULL exampe_text: 740\n","--------------------------------------------------------------------------------\n","           Display Dataframe Metadata\n","--------------------------------------------------------------------------------\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 740 entries, 0 to 739\n","Data columns (total 5 columns):\n"," #   Column        Non-Null Count  Dtype \n","---  ------        --------------  ----- \n"," 0   Category      740 non-null    object\n"," 1   function      740 non-null    object\n"," 2   feature_desc  730 non-null    object\n"," 3   example_text  740 non-null    object\n"," 4   link          740 non-null    object\n","dtypes: object(5)\n","memory usage: 29.0+ KB\n","--------------------------------------------------------------------------------\n","           Display Dataframe post removing rows with NULL example_text\n","--------------------------------------------------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["        Category                             function  \\\n","0  Configuration       pyspark.sql.conf.RuntimeConfig   \n","1   Input/Output      pyspark.sql.DataFrameReader.csv   \n","2   Input/Output   pyspark.sql.DataFrameReader.format   \n","3   Input/Output     pyspark.sql.DataFrameReader.jdbc   \n","4   Input/Output     pyspark.sql.DataFrameReader.json   \n","5   Input/Output     pyspark.sql.DataFrameReader.load   \n","6   Input/Output   pyspark.sql.DataFrameReader.option   \n","7   Input/Output  pyspark.sql.DataFrameReader.options   \n","8   Input/Output      pyspark.sql.DataFrameReader.orc   \n","9   Input/Output  pyspark.sql.DataFrameReader.parquet   \n","\n","                                        feature_desc  \\\n","0  User facing configuration API  accessible thro...   \n","1  Loads a CSV file and returns the result as a  ...   \n","2            Specifies the input data source format.   \n","3  Construct a DataFrame representing the databas...   \n","4  Loads JSON files and returns the results as a ...   \n","5  Loads data from a data source and returns it a...   \n","6  Adds an input option for the underlying data s...   \n","7  Adds input options for the underlying data sou...   \n","8  Loads ORC files  returning the result as a Dat...   \n","9  Loads Parquet files  returning the result as a...   \n","\n","                                        example_text  \\\n","0   # User-facing configuration API, accessible t...   \n","1   # Write a DataFrame into a CSV file and read ...   \n","2  <br>>>> spark.read.format('json')<br><...readw...   \n","3   # Construct a DataFrame representing the data...   \n","4   # Write a DataFrame into a JSON file and read...   \n","5   # Load a CSV file with format, schema and opt...   \n","6  <br>>>> spark.read.option(\"key\", \"value\")<br><...   \n","7  <br>>>> spark.read.option(\"key\", \"value\")<br><...   \n","8   # Write a DataFrame into a ORC file and read ...   \n","9   # Write a DataFrame into a Parquet file and r...   \n","\n","                                                link  \n","0  https://spark.apache.org/docs/latest/api/pytho...  \n","1  https://spark.apache.org/docs/latest/api/pytho...  \n","2  https://spark.apache.org/docs/latest/api/pytho...  \n","3  https://spark.apache.org/docs/latest/api/pytho...  \n","4  https://spark.apache.org/docs/latest/api/pytho...  \n","5  https://spark.apache.org/docs/latest/api/pytho...  \n","6  https://spark.apache.org/docs/latest/api/pytho...  \n","7  https://spark.apache.org/docs/latest/api/pytho...  \n","8  https://spark.apache.org/docs/latest/api/pytho...  \n","9  https://spark.apache.org/docs/latest/api/pytho...  "],"text/html":["\n","  <div id=\"df-fffd4253-d8b2-4299-92fb-23c8e4764552\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>function</th>\n","      <th>feature_desc</th>\n","      <th>example_text</th>\n","      <th>link</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Configuration</td>\n","      <td>pyspark.sql.conf.RuntimeConfig</td>\n","      <td>User facing configuration API  accessible thro...</td>\n","      <td># User-facing configuration API, accessible t...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","      <td>Loads a CSV file and returns the result as a  ...</td>\n","      <td># Write a DataFrame into a CSV file and read ...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.format</td>\n","      <td>Specifies the input data source format.</td>\n","      <td>&lt;br&gt;&gt;&gt;&gt; spark.read.format('json')&lt;br&gt;&lt;...readw...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.jdbc</td>\n","      <td>Construct a DataFrame representing the databas...</td>\n","      <td># Construct a DataFrame representing the data...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.json</td>\n","      <td>Loads JSON files and returns the results as a ...</td>\n","      <td># Write a DataFrame into a JSON file and read...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.load</td>\n","      <td>Loads data from a data source and returns it a...</td>\n","      <td># Load a CSV file with format, schema and opt...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.option</td>\n","      <td>Adds an input option for the underlying data s...</td>\n","      <td>&lt;br&gt;&gt;&gt;&gt; spark.read.option(\"key\", \"value\")&lt;br&gt;&lt;...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.options</td>\n","      <td>Adds input options for the underlying data sou...</td>\n","      <td>&lt;br&gt;&gt;&gt;&gt; spark.read.option(\"key\", \"value\")&lt;br&gt;&lt;...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.orc</td>\n","      <td>Loads ORC files  returning the result as a Dat...</td>\n","      <td># Write a DataFrame into a ORC file and read ...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.parquet</td>\n","      <td>Loads Parquet files  returning the result as a...</td>\n","      <td># Write a DataFrame into a Parquet file and r...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fffd4253-d8b2-4299-92fb-23c8e4764552')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fffd4253-d8b2-4299-92fb-23c8e4764552 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fffd4253-d8b2-4299-92fb-23c8e4764552');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-dcd6261d-1a01-40d2-a130-22a4a94672b9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dcd6261d-1a01-40d2-a130-22a4a94672b9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-dcd6261d-1a01-40d2-a130-22a4a94672b9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_init","summary":"{\n  \"name\": \"df_init\",\n  \"rows\": 740,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"Collection Functions\",\n          \"UDF\",\n          \"Datetime Functions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"function\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 703,\n        \"samples\": [\n          \"pyspark.sql.functions.stddev_samp\",\n          \"pyspark.sql.Column.bitwiseXOR\",\n          \"pyspark.sql.DataFrame.createGlobalTempView\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_desc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 638,\n        \"samples\": [\n          \"Computes tangent of the input column.\",\n          \"Computes cosine of the input column.\",\n          \"Add write options.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"example_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 679,\n        \"samples\": [\n          \"<br>>>> spark.catalog.currentDatabase()<br>'default'<br> \",\n          \"<br>>>> df = spark.createDataFrame([(\\\"2016-03-11 09:00:07\\\", 1)]).toDF(\\\"date\\\", \\\"val\\\")<br>>>> w = df.groupBy(session_window(\\\"date\\\", \\\"5 seconds\\\")).agg(sum(\\\"val\\\").alias(\\\"sum\\\"))<br>>>> w.select(w.session_window.start.cast(\\\"string\\\").alias(\\\"start\\\"),<br>...          w.session_window.end.cast(\\\"string\\\").alias(\\\"end\\\"), \\\"sum\\\").collect()<br>[Row(start='2016-03-11 09:00:07', end='2016-03-11 09:00:12', sum=1)]<br>>>> w = df.groupBy(session_window(\\\"date\\\", lit(\\\"5 seconds\\\"))).agg(sum(\\\"val\\\").alias(\\\"sum\\\"))<br>>>> w.select(w.session_window.start.cast(\\\"string\\\").alias(\\\"start\\\"),<br>...          w.session_window.end.cast(\\\"string\\\").alias(\\\"end\\\"), \\\"sum\\\").collect()<br>[Row(start='2016-03-11 09:00:07', end='2016-03-11 09:00:12', sum=1)]<br> \",\n          \"<br>>>> from pyspark.sql import Row<br>>>> from pyspark.sql.functions import col, lit<br>>>> df = spark.createDataFrame(<br>...     [(14, \\\"Tom\\\"), (23, \\\"Alice\\\"), (16, \\\"Bob\\\")], [\\\"age\\\", \\\"name\\\"])<br>>>> df2 = spark.createDataFrame([Row(height=80, name=\\\"Tom\\\"), Row(height=85, name=\\\"Bob\\\")])<br><br>>>> df.drop('age').show()<br>+-----+<br>| name|<br>+-----+<br>|  Tom|<br>|Alice|<br>|  Bob|<br>+-----+<br>>>> df.drop(df.age).show()<br>+-----+<br>| name|<br>+-----+<br>|  Tom|<br>|Alice|<br>|  Bob|<br>+-----+<br> # Drop the column that joined both DataFrames on.<br>>>> df.join(df2, df.name == df2.name, 'inner').drop('name').sort('age').show()<br>+---+------+<br>|age|height|<br>+---+------+<br>| 14|    80|<br>| 16|    85|<br>+---+------+<br><br>>>> df3 = df.join(df2)<br>>>> df3.show()<br>+---+-----+------+----+<br>|age| name|height|name|<br>+---+-----+------+----+<br>| 14|  Tom|    80| Tom|<br>| 14|  Tom|    85| Bob|<br>| 23|Alice|    80| Tom|<br>| 23|Alice|    85| Bob|<br>| 16|  Bob|    80| Tom|<br>| 16|  Bob|    85| Bob|<br>+---+-----+------+----+<br> # Drop two column by the same name.<br>>>> df3.drop(\\\"name\\\").show()<br>+---+------+<br>|age|height|<br>+---+------+<br>| 14|    80|<br>| 14|    85|<br>| 23|    80|<br>| 23|    85|<br>| 16|    80|<br>| 16|    85|<br>+---+------+<br> # Can not drop col(\\u00e2\\u0080\\u0098name\\u00e2\\u0080\\u0099) due to ambiguous reference.<br>>>> df3.drop(col(\\\"name\\\")).show()<br>Traceback (most recent call last):<br>...<br>pyspark.errors.exceptions.captured.AnalysisException: [AMBIGUOUS_REFERENCE] Reference...<br><br>>>> df4 = df.withColumn(\\\"a.b.c\\\", lit(1))<br>>>> df4.show()<br>+---+-----+-----+<br>|age| name|a.b.c|<br>+---+-----+-----+<br>| 14|  Tom|    1|<br>| 23|Alice|    1|<br>| 16|  Bob|    1|<br>+---+-----+-----+<br><br>>>> df4.drop(\\\"a.b.c\\\").show()<br>+---+-----+<br>|age| name|<br>+---+-----+<br>| 14|  Tom|<br>| 23|Alice|<br>| 16|  Bob|<br>+---+-----+<br> # Can not find a column matching the expression \\u00e2\\u0080\\u009ca.b.c\\u00e2\\u0080\\u009d.<br>>>> df4.drop(col(\\\"a.b.c\\\")).show()<br>+---+-----+-----+<br>|age| name|a.b.c|<br>+---+-----+-----+<br>| 14|  Tom|    1|<br>| 23|Alice|    1|<br>| 16|  Bob|    1|<br>+---+-----+-----+<br> \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 703,\n        \"samples\": [\n          \"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.stddev_samp.html#pyspark.sql.functions.stddev_samp\",\n          \"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.bitwiseXOR.html\",\n          \"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.createGlobalTempView.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# SPLIT EXAMPLE TEXT INTO CODE UNIQUE EXAMPLES\n","\n","import re\n","import string\n","\n","def remove_unwanted_text(code_text):\n","  filtered_code = ''\n","  for index, line in enumerate(code_text.split('<br>')):\n","    line = line.strip()\n","    if line.strip().startswith(('>>>', '...', '#')) \\\n","      and not line.startswith(('+', '|')):\n","      filtered_code = filtered_code + line.replace('>>> ', '') + '<br>' #+ f'{index}:  .replace('...', '   ')\n","  return filtered_code\n","\n","# and not 'show(' in line \\\n","\n","df_init_pass_1 = df_init.copy()\n","df_init_pass_1['seq'] = range(1, len(df_init_pass_1) + 1)\n","df_init_pass_1['example_text'] = df_init_pass_1['example_text'].apply(remove_unwanted_text)\n","df_init_pass_1['example_text'] = df_init_pass_1['example_text'].apply(lambda x: ''.join(filter(lambda char: char in string.printable, x)))\n","df_init_pass_1['example_text_bkp'] = df_init_pass_1['example_text']\n","df_init_pass_1['example_text'] = df_init_pass_1.apply(lambda x: '' if x['example_text'].strip().startswith('#') and len( list(filter(None, x['example_text'].split('<br>'))) ) <= 1 else x['example_text'], axis=1)\n","df_init_pass_1.head()#.style.set_properties(**{'text-align': 'left'})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"uoyLieNNG90A","executionInfo":{"status":"ok","timestamp":1709782100931,"user_tz":-330,"elapsed":28,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"3b95303e-e046-40c7-a61c-4f784041eab3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Category                            function  \\\n","0  Configuration      pyspark.sql.conf.RuntimeConfig   \n","1   Input/Output     pyspark.sql.DataFrameReader.csv   \n","2   Input/Output  pyspark.sql.DataFrameReader.format   \n","3   Input/Output    pyspark.sql.DataFrameReader.jdbc   \n","4   Input/Output    pyspark.sql.DataFrameReader.json   \n","\n","                                        feature_desc  \\\n","0  User facing configuration API  accessible thro...   \n","1  Loads a CSV file and returns the result as a  ...   \n","2            Specifies the input data source format.   \n","3  Construct a DataFrame representing the databas...   \n","4  Loads JSON files and returns the results as a ...   \n","\n","                                        example_text  \\\n","0                                                      \n","1  # Write a DataFrame into a CSV file and read i...   \n","2  spark.read.format('json')<br># Write a DataFra...   \n","3                                                      \n","4  # Write a DataFrame into a JSON file and read ...   \n","\n","                                                link  seq  \\\n","0  https://spark.apache.org/docs/latest/api/pytho...    1   \n","1  https://spark.apache.org/docs/latest/api/pytho...    2   \n","2  https://spark.apache.org/docs/latest/api/pytho...    3   \n","3  https://spark.apache.org/docs/latest/api/pytho...    4   \n","4  https://spark.apache.org/docs/latest/api/pytho...    5   \n","\n","                                    example_text_bkp  \n","0  # User-facing configuration API, accessible th...  \n","1  # Write a DataFrame into a CSV file and read i...  \n","2  spark.read.format('json')<br># Write a DataFra...  \n","3  # Construct a DataFrame representing the datab...  \n","4  # Write a DataFrame into a JSON file and read ...  "],"text/html":["\n","  <div id=\"df-6349fd1a-1fce-4cd6-a765-dfc30ad7ee62\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>function</th>\n","      <th>feature_desc</th>\n","      <th>example_text</th>\n","      <th>link</th>\n","      <th>seq</th>\n","      <th>example_text_bkp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Configuration</td>\n","      <td>pyspark.sql.conf.RuntimeConfig</td>\n","      <td>User facing configuration API  accessible thro...</td>\n","      <td></td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","      <td>1</td>\n","      <td># User-facing configuration API, accessible th...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","      <td>Loads a CSV file and returns the result as a  ...</td>\n","      <td># Write a DataFrame into a CSV file and read i...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","      <td>2</td>\n","      <td># Write a DataFrame into a CSV file and read i...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.format</td>\n","      <td>Specifies the input data source format.</td>\n","      <td>spark.read.format('json')&lt;br&gt;# Write a DataFra...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","      <td>3</td>\n","      <td>spark.read.format('json')&lt;br&gt;# Write a DataFra...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.jdbc</td>\n","      <td>Construct a DataFrame representing the databas...</td>\n","      <td></td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","      <td>4</td>\n","      <td># Construct a DataFrame representing the datab...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.json</td>\n","      <td>Loads JSON files and returns the results as a ...</td>\n","      <td># Write a DataFrame into a JSON file and read ...</td>\n","      <td>https://spark.apache.org/docs/latest/api/pytho...</td>\n","      <td>5</td>\n","      <td># Write a DataFrame into a JSON file and read ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6349fd1a-1fce-4cd6-a765-dfc30ad7ee62')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6349fd1a-1fce-4cd6-a765-dfc30ad7ee62 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6349fd1a-1fce-4cd6-a765-dfc30ad7ee62');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c57e787d-01ea-483b-bd2e-7a8e6278197c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c57e787d-01ea-483b-bd2e-7a8e6278197c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c57e787d-01ea-483b-bd2e-7a8e6278197c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_init_pass_1","summary":"{\n  \"name\": \"df_init_pass_1\",\n  \"rows\": 740,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"Collection Functions\",\n          \"UDF\",\n          \"Datetime Functions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"function\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 703,\n        \"samples\": [\n          \"pyspark.sql.functions.stddev_samp\",\n          \"pyspark.sql.Column.bitwiseXOR\",\n          \"pyspark.sql.DataFrame.createGlobalTempView\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_desc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 638,\n        \"samples\": [\n          \"Computes tangent of the input column.\",\n          \"Computes cosine of the input column.\",\n          \"Add write options.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"example_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 621,\n        \"samples\": [\n          \"from pyspark.sql import Row<br>from pyspark.sql.functions import col, lit<br>df = spark.createDataFrame(<br>...     [(14, \\\"Tom\\\"), (23, \\\"Alice\\\"), (16, \\\"Bob\\\")], [\\\"age\\\", \\\"name\\\"])<br>df2 = spark.createDataFrame([Row(height=80, name=\\\"Tom\\\"), Row(height=85, name=\\\"Bob\\\")])<br>df.drop('age').show()<br>df.drop(df.age).show()<br># Drop the column that joined both DataFrames on.<br>df.join(df2, df.name == df2.name, 'inner').drop('name').sort('age').show()<br>df3 = df.join(df2)<br>df3.show()<br># Drop two column by the same name.<br>df3.drop(\\\"name\\\").show()<br># Can not drop col(name) due to ambiguous reference.<br>df3.drop(col(\\\"name\\\")).show()<br>...<br>df4 = df.withColumn(\\\"a.b.c\\\", lit(1))<br>df4.show()<br>df4.drop(\\\"a.b.c\\\").show()<br># Can not find a column matching the expression a.b.c.<br>df4.drop(col(\\\"a.b.c\\\")).show()<br>\",\n          \"df = spark.createDataFrame([<br>...     (2, \\\"Alice\\\", 80), (3, \\\"Alice\\\", 100),<br>...     (5, \\\"Bob\\\", 120), (10, \\\"Bob\\\", 140)], [\\\"age\\\", \\\"name\\\", \\\"height\\\"])<br>df.show()<br># Group-by name, and calculate the min of the age in each group.<br>df.groupBy(\\\"name\\\").min(\\\"age\\\").sort(\\\"name\\\").show()<br># Calculate the min of the age and height in all data.<br>df.groupBy().min(\\\"age\\\", \\\"height\\\").show()<br>\",\n          \"from pyspark.sql import Row<br>df = spark.createDataFrame([<br>...     Row(age=10, height=80, name=\\\"Alice\\\"),<br>...     Row(age=5, height=None, name=\\\"Bob\\\"),<br>...     Row(age=None, height=None, name=\\\"Tom\\\"),<br>...     Row(age=None, height=None, name=None),<br>... ])<br>splits = df.randomSplit([1.0, 2.0], 24)<br>splits[0].count()<br>splits[1].count()<br>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 703,\n        \"samples\": [\n          \"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.stddev_samp.html#pyspark.sql.functions.stddev_samp\",\n          \"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.bitwiseXOR.html\",\n          \"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.createGlobalTempView.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seq\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 213,\n        \"min\": 1,\n        \"max\": 740,\n        \"num_unique_values\": 740,\n        \"samples\": [\n          121,\n          417,\n          335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"example_text_bkp\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 679,\n        \"samples\": [\n          \"spark.catalog.currentDatabase()<br>\",\n          \"df = spark.createDataFrame([(\\\"2016-03-11 09:00:07\\\", 1)]).toDF(\\\"date\\\", \\\"val\\\")<br>w = df.groupBy(session_window(\\\"date\\\", \\\"5 seconds\\\")).agg(sum(\\\"val\\\").alias(\\\"sum\\\"))<br>w.select(w.session_window.start.cast(\\\"string\\\").alias(\\\"start\\\"),<br>...          w.session_window.end.cast(\\\"string\\\").alias(\\\"end\\\"), \\\"sum\\\").collect()<br>w = df.groupBy(session_window(\\\"date\\\", lit(\\\"5 seconds\\\"))).agg(sum(\\\"val\\\").alias(\\\"sum\\\"))<br>w.select(w.session_window.start.cast(\\\"string\\\").alias(\\\"start\\\"),<br>...          w.session_window.end.cast(\\\"string\\\").alias(\\\"end\\\"), \\\"sum\\\").collect()<br>\",\n          \"from pyspark.sql import Row<br>from pyspark.sql.functions import col, lit<br>df = spark.createDataFrame(<br>...     [(14, \\\"Tom\\\"), (23, \\\"Alice\\\"), (16, \\\"Bob\\\")], [\\\"age\\\", \\\"name\\\"])<br>df2 = spark.createDataFrame([Row(height=80, name=\\\"Tom\\\"), Row(height=85, name=\\\"Bob\\\")])<br>df.drop('age').show()<br>df.drop(df.age).show()<br># Drop the column that joined both DataFrames on.<br>df.join(df2, df.name == df2.name, 'inner').drop('name').sort('age').show()<br>df3 = df.join(df2)<br>df3.show()<br># Drop two column by the same name.<br>df3.drop(\\\"name\\\").show()<br># Can not drop col(name) due to ambiguous reference.<br>df3.drop(col(\\\"name\\\")).show()<br>...<br>df4 = df.withColumn(\\\"a.b.c\\\", lit(1))<br>df4.show()<br>df4.drop(\\\"a.b.c\\\").show()<br># Can not find a column matching the expression a.b.c.<br>df4.drop(col(\\\"a.b.c\\\")).show()<br>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# REMOVE ALL ROWS WITH NULL VALUES OF EXAMPLE_TEXT\n","\n","fn_display_message(f' --> Initial Count : {df_init_pass_1.shape[0]}')\n","df_init_pass_1 = df_init_pass_1.dropna(subset=['example_text'])\n","fn_display_message(f' --> Count post dropping NULL exampe_text: {df_init_pass_1.shape[0]}')\n","\n","df_init_pass_1 = df_init_pass_1[df_init_pass_1['example_text'].replace(r'^\\s*$', '') != '']\n","fn_display_message(f' --> Count post dropping BLANK exampe_text: {df_init_pass_1.shape[0]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ij044hGJ38_p","executionInfo":{"status":"ok","timestamp":1709782100932,"user_tz":-330,"elapsed":27,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"a6291953-79a2-445f-bb59-31708cab4987"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" --> Initial Count : 740\n"," --> Count post dropping NULL exampe_text: 740\n"," --> Count post dropping BLANK exampe_text: 669\n"]}]},{"cell_type":"code","source":["# Verify rows where example_text was set to blanks explicitly. Note that example_text_bkp should not have any code lines for this validation\n","df_init_pass_1[['example_text', 'example_text_bkp', 'Category', 'function', 'feature_desc']][df_init_pass_1['example_text'] == ''].head().style.set_properties(**{'text-align': 'left'})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"id":"VYIMxH_oGI64","executionInfo":{"status":"ok","timestamp":1709782101462,"user_tz":-330,"elapsed":554,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"cd42a43b-ddc9-48b2-be4f-d6d21e0098fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7d47badaa440>"],"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_ac6a1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_ac6a1_level0_col0\" class=\"col_heading level0 col0\" >example_text</th>\n","      <th id=\"T_ac6a1_level0_col1\" class=\"col_heading level0 col1\" >example_text_bkp</th>\n","      <th id=\"T_ac6a1_level0_col2\" class=\"col_heading level0 col2\" >Category</th>\n","      <th id=\"T_ac6a1_level0_col3\" class=\"col_heading level0 col3\" >function</th>\n","      <th id=\"T_ac6a1_level0_col4\" class=\"col_heading level0 col4\" >feature_desc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# FILTER AND KEEP DESIRED FUNCTIONS\n","df_init_pass_2 = df_init_pass_1[['seq', 'feature_desc', 'example_text', 'Category', 'function']].copy()\n","\n","filter_values = [\n","  'Input/Output',\n","  'DataFrame',\n","  'Normal Functions',\n","  'Math Functions',\n","  'Datetime Functions',\n","  'Collection Functions',\n","  'Partition Transformation Functions',\n","  'Aggregate Functions',\n","  'Window Functions',\n","  'Sort Functions',\n","  'String Functions',\n","  'Bitwise Functions',\n","  'Call Functions',\n","  'Misc Functions',\n","  'Predicate Functions',\n","  'Xml Functions',\n","  'Window',\n","  'Grouping'\n","    ]\n","\n","df_init_pass_2 = df_init_pass_2[df_init_pass_2['Category'].isin(filter_values)]\n","df_init_pass_2.head(10)#.style.set_properties(**{'text-align': 'left'})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"gQ3_kdHrvWGM","executionInfo":{"status":"ok","timestamp":1709782101462,"user_tz":-330,"elapsed":33,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"eaff663b-1a6c-4a05-c44a-e8e6575a1e03"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    seq                                       feature_desc  \\\n","1     2  Loads a CSV file and returns the result as a  ...   \n","2     3            Specifies the input data source format.   \n","4     5  Loads JSON files and returns the results as a ...   \n","5     6  Loads data from a data source and returns it a...   \n","6     7  Adds an input option for the underlying data s...   \n","7     8  Adds input options for the underlying data sou...   \n","8     9  Loads ORC files  returning the result as a Dat...   \n","9    10  Loads Parquet files  returning the result as a...   \n","10   11  Specifies the input schema. Some data sources ...   \n","11   12        Returns the specified table as a DataFrame.   \n","\n","                                         example_text      Category  \\\n","1   # Write a DataFrame into a CSV file and read i...  Input/Output   \n","2   spark.read.format('json')<br># Write a DataFra...  Input/Output   \n","4   # Write a DataFrame into a JSON file and read ...  Input/Output   \n","5   # Load a CSV file with format, schema and opti...  Input/Output   \n","6   spark.read.option(\"key\", \"value\")<br># Specify...  Input/Output   \n","7   spark.read.option(\"key\", \"value\")<br># Specify...  Input/Output   \n","8   # Write a DataFrame into a ORC file and read i...  Input/Output   \n","9   # Write a DataFrame into a Parquet file and re...  Input/Output   \n","10  spark.read.schema(\"col0 INT, col1 DOUBLE\")<br>...  Input/Output   \n","11  df = spark.range(10)<br>df.createOrReplaceTemp...  Input/Output   \n","\n","                               function  \n","1       pyspark.sql.DataFrameReader.csv  \n","2    pyspark.sql.DataFrameReader.format  \n","4      pyspark.sql.DataFrameReader.json  \n","5      pyspark.sql.DataFrameReader.load  \n","6    pyspark.sql.DataFrameReader.option  \n","7   pyspark.sql.DataFrameReader.options  \n","8       pyspark.sql.DataFrameReader.orc  \n","9   pyspark.sql.DataFrameReader.parquet  \n","10   pyspark.sql.DataFrameReader.schema  \n","11    pyspark.sql.DataFrameReader.table  "],"text/html":["\n","  <div id=\"df-f18b8c4f-63ee-4dd4-ac58-076f970129ee\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>seq</th>\n","      <th>feature_desc</th>\n","      <th>example_text</th>\n","      <th>Category</th>\n","      <th>function</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Loads a CSV file and returns the result as a  ...</td>\n","      <td># Write a DataFrame into a CSV file and read i...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Specifies the input data source format.</td>\n","      <td>spark.read.format('json')&lt;br&gt;# Write a DataFra...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.format</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Loads JSON files and returns the results as a ...</td>\n","      <td># Write a DataFrame into a JSON file and read ...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.json</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>Loads data from a data source and returns it a...</td>\n","      <td># Load a CSV file with format, schema and opti...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.load</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>Adds an input option for the underlying data s...</td>\n","      <td>spark.read.option(\"key\", \"value\")&lt;br&gt;# Specify...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.option</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>Adds input options for the underlying data sou...</td>\n","      <td>spark.read.option(\"key\", \"value\")&lt;br&gt;# Specify...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.options</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>Loads ORC files  returning the result as a Dat...</td>\n","      <td># Write a DataFrame into a ORC file and read i...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.orc</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>Loads Parquet files  returning the result as a...</td>\n","      <td># Write a DataFrame into a Parquet file and re...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.parquet</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>Specifies the input schema. Some data sources ...</td>\n","      <td>spark.read.schema(\"col0 INT, col1 DOUBLE\")&lt;br&gt;...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.schema</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>Returns the specified table as a DataFrame.</td>\n","      <td>df = spark.range(10)&lt;br&gt;df.createOrReplaceTemp...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.table</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f18b8c4f-63ee-4dd4-ac58-076f970129ee')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f18b8c4f-63ee-4dd4-ac58-076f970129ee button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f18b8c4f-63ee-4dd4-ac58-076f970129ee');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-26465acf-6ea2-4904-8871-1c7fa344f988\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26465acf-6ea2-4904-8871-1c7fa344f988')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-26465acf-6ea2-4904-8871-1c7fa344f988 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_init_pass_2","summary":"{\n  \"name\": \"df_init_pass_2\",\n  \"rows\": 599,\n  \"fields\": [\n    {\n      \"column\": \"seq\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 198,\n        \"min\": 2,\n        \"max\": 700,\n        \"num_unique_values\": 599,\n        \"samples\": [\n          129,\n          510,\n          657\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_desc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 520,\n        \"samples\": [\n          \"Returns an array of elements after applying a transformation to each element in the input array.\",\n          \"Projects a set of SQL expressions and returns a new DataFrame. This is a variant of select   that accepts SQL expressions.\",\n          \"Loads ORC files  returning the result as a DataFrame.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"example_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 550,\n        \"samples\": [\n          \"df = spark.createDataFrame([(6000, 15), (1990, 2)], [\\\"a\\\", \\\"b\\\"])<br>df.select(try_multiply(df.a, df.b).alias('r')).collect()<br>df = spark.createDataFrame([(2, 3),], [\\\"a\\\", \\\"b\\\"])<br>df.select(try_multiply(make_interval(df.a), df.b).alias('r')).show(truncate=False)<br>\",\n          \"df = spark.range(1)<br>df.persist()<br>df.explain()<br># Persists the data in the disk by specifying the storage level.<br>from pyspark.storagelevel import StorageLevel<br>df.persist(StorageLevel.DISK_ONLY)<br>\",\n          \"df = spark.createDataFrame([(\\\"https://spark.apache.org\\\",)], [\\\"a\\\"])<br>df.select(url_encode(df.a).alias('r')).collect()<br>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"Input/Output\",\n          \"DataFrame\",\n          \"Window Functions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"function\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 562,\n        \"samples\": [\n          \"pyspark.sql.functions.translate\",\n          \"pyspark.sql.functions.position\",\n          \"pyspark.sql.functions.variance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["fn_display_header('All Initial Passes Completed. Final Pass: df_final_pass')\n","df_final_pass = df_init_pass_2.copy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vitD4HvNVCS5","executionInfo":{"status":"ok","timestamp":1709782101462,"user_tz":-330,"elapsed":29,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"87c56b91-9df5-4fb2-b416-4ecf8a943a4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","           All Initial Passes Completed. Final Pass: df_final_pass\n","--------------------------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["<br>\n","<br>\n","<br>\n","\n","----\n","# <b> START CODE/COMMENT HANDLING: </b>\n","----\n","<br>"],"metadata":{"id":"MPDDkNN5NTX4"}},{"cell_type":"code","source":["# SPLIT CODE INTO COMMENTS AND TEXT\n","\n","# Function to split the code text into an array separated by individual comments\n","def fn_split_comments(code_text, ignore_index0):\n","  result_list = []\n","  codes = []\n","  prev_line = ''\n","  code_text_mod = ''\n","\n","  # Below code merges adjacent comment lines into a single line\n","  for index, line in enumerate(code_text.split('<br>')):\n","    if prev_line.replace('...', '').strip().startswith('#') and line.replace('...', '').strip().startswith('#'):\n","      line = line.replace('    #', '--REPLACE--')\n","    code_text_mod = code_text_mod + line + '<br>'\n","    prev_line = line\n","  code_text_mod = code_text_mod.replace('<br>... --REPLACE--', '')\n","\n","  # Below code splits the text on '    #' and returns an array. First element in the array is ignored\n","  #if code_text_mod.strip().startswith('#'):\n","    #code_text_mod = code_text_mod.replace('#', ' ', 1)\n","  if '#' in code_text_mod:\n","    for index, line in enumerate(code_text_mod.split('#')):\n","      if ignore_index0 == 'Y':\n","        if index == 0:\n","          pass\n","        else:\n","          text = ('#' + line + '<br>')\n","          result_list.append(text)\n","      else:\n","        if index == 0:\n","          text = (line + '<br>')\n","          result_list.append(text)\n","        else:\n","          text = ('#' + line + '<br>')\n","          result_list.append(text)\n","  else:\n","    result_list = [code_text_mod]\n","  return (result_list)\n","\n","# Function for INPUT/OUTPUT to massage the code_text in order to separate the comments and the corresponding code. It will be use to separate them into two different columns\n","def fn_input_output_cleanse(code_text, flag):\n","  code_text\n","  result = ''\n","  for index, line in enumerate(code_text.split('<br>')):\n","    line = line.replace('...', '').strip()\n","    line = line.replace('df.printSchema()', '')\n","    line = line.replace('df.show()', '')\n","\n","    if len(line) != 0:\n","      if flag == 'COMMENT' and line.startswith('#'):\n","        result = line.replace('#', 'Pyspark code to ')\n","      if flag != 'COMMENT' and not line.startswith('#') \\\n","        and not line.startswith('df = spark.createDataFrame([') \\\n","        and 'df = spark.createDataFrame([{\"age\": 100, \"name\": \"Hyukjin Kwon\"}])' not in line \\\n","        and 'import tempfile' not in line \\\n","        and 'import os' not in line \\\n","        and 'TemporaryDirectory()' not in line:\n","        line = line.replace('.show()', '')\n","        result = result + line + '<br>'\n","\n","  if flag != 'COMMENT':\n","    result = result.replace('spark.createDataFrame(<br>[{\"age\": 100, \"name\": \"Hyukjin Kwon\"}]<br>)', 'df')\n","    result = result.replace('(<br>', '(').replace('<br>)', ')')\n","    #if '.save(d)' in result or '.load(d)' in result or '.json(d)' in result:\n","    result = result.replace('.save(d)', '.save(my_dir)')\n","    result = result.replace('.load(d)', '.load(my_dir)')\n","    result = result.replace('.json(d)', '.json(my_dir)')\n","    result = result.replace('.orc(d)', '.orc(my_dir)')\n","    result = result.replace('.parquet(d)', '.parquet(my_dir)')\n","    result = result.replace('.text(d)', '.text(my_dir)')\n","    result = result.replace('(d,', '(my_dir,')\n","    result = re.sub(r'\\.sort\\([^)]*\\)', '', result)\n","    if result.startswith('spark.read'):\n","      result = result.replace('spark.read', 'df = spark.read')\n","\n","    result = re.sub(r'spark\\.createDataFrame\\(\\[.*?\\]\\).write', 'df.write', result)  # this should be done last\n","    if 'df.write' not in result:\n","      result = re.sub(r'spark\\.createDataFrame\\(\\[.*?\\]\\)', 'df = df', result)  # this should be done last\n","  return result\n","\n","# Create initial copy of dataframe for only Category = 'Input/Output'\n","df_input_output = df_final_pass[df_final_pass['Category'].isin(['Input/Output'])].copy().set_index('seq')\n","\n","# Split code text based on comments\n","df_input_output['example_text_1'] = df_input_output['example_text'].apply(lambda x: fn_split_comments(x, 'Y'))\n","\n","# Normalize the code based on the elements in the array derived above for column\n","fn_display_message(f' --> Display Count Before Explode: {df_input_output.shape[0]}')\n","df_input_output = df_input_output.explode('example_text_1')\n","df_input_output['seq'] = range(1, len(df_input_output) + 1)\n","df_input_output = df_input_output.set_index('seq')\n","fn_display_message(f' --> Display Count After Explode: {df_input_output.shape[0]}')\n","\n","# Derive code_snippet and code_description\n","df_input_output['code_description'] = df_input_output['example_text_1'].apply(lambda x: fn_input_output_cleanse(x, 'COMMENT'))\n","df_input_output['code_snippet'] = df_input_output['example_text_1'].apply(lambda x: fn_input_output_cleanse(x, 'CODE'))\n","\n","# Drop all blank code_snippet\n","df_input_output = df_input_output[df_input_output['code_snippet'].replace('<br>', '') != '']\n","fn_display_message(f' --> Display Count After dropping blank code_snippet: {df_input_output.shape[0]}')\n","\n","# Handle Blank code_description Normalize the code based on the elements in the array derived for code_description\n","df_input_output['code_description'] = df_input_output.apply(lambda x: [x['code_description'], 'Pyspark code which ' + x['feature_desc']], axis=1)\n","\n","# Add import_line column with blanks\n","df_input_output['import_line'] = ''\n","\n","# Normalize/explode data on code_description\n","df_input_output = df_input_output.explode('code_description')\n","df_input_output['seq'] = range(1, len(df_input_output) + 1)\n","df_input_output = df_input_output.set_index('seq')\n","fn_display_message(f' --> Display Count After Explode on comments: {df_input_output.shape[0]}')\n","\n","df_input_output = df_input_output[df_input_output['code_description'].replace('<br>', '') != '']\n","fn_display_message(f' --> Display Count After dropping blank code_description: {df_input_output.shape[0]}')\n","\n","# Drop code snippets with more than 3 lines\n","df_input_output = df_input_output[df_input_output['code_snippet'].str.split('<br>').str.len() <= 3]\n","fn_display_message(f' --> Display Count After dropping code snippets with more than 3 lines: {df_input_output.shape[0]}')\n","\n","# Drop rows which are difficult to process\n","df_input_output = df_input_output[~df_input_output['example_text'].str.contains('DROP TABLE')]\n","fn_display_message(f' --> Display Count After dropping complicated code: {df_input_output.shape[0]}')\n","\n","# Convert all code_snippet into single line\n","df_input_output['code_snippet'] = df_input_output['code_snippet'].apply(lambda x: x.replace('<br>', '').replace('\\n', ''))\n","\n","#df_input_output = df_input_output[['code_description', 'code_snippet', 'import_line', 'example_text_1', 'function']] #, 'example_text', 'feature_desc', 'Category', 'function']]\n","df_input_output.head()#.style.set_properties(**{'text-align': 'left'})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446},"id":"zUlTvKQ1bsvy","executionInfo":{"status":"ok","timestamp":1709782101463,"user_tz":-330,"elapsed":26,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"8331e609-d992-4dde-e556-40695bcad721"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" --> Display Count Before Explode: 26\n"," --> Display Count After Explode: 74\n"," --> Display Count After dropping blank code_snippet: 55\n"," --> Display Count After Explode on comments: 110\n"," --> Display Count After dropping blank code_description: 109\n"," --> Display Count After dropping code snippets with more than 3 lines: 102\n"," --> Display Count After dropping complicated code: 90\n"]},{"output_type":"execute_result","data":{"text/plain":["                                          feature_desc  \\\n","seq                                                      \n","1    Loads a CSV file and returns the result as a  ...   \n","2    Loads a CSV file and returns the result as a  ...   \n","3    Loads a CSV file and returns the result as a  ...   \n","4    Loads a CSV file and returns the result as a  ...   \n","5              Specifies the input data source format.   \n","\n","                                          example_text      Category  \\\n","seq                                                                    \n","1    # Write a DataFrame into a CSV file and read i...  Input/Output   \n","2    # Write a DataFrame into a CSV file and read i...  Input/Output   \n","3    # Write a DataFrame into a CSV file and read i...  Input/Output   \n","4    # Write a DataFrame into a CSV file and read i...  Input/Output   \n","5    spark.read.format('json')<br># Write a DataFra...  Input/Output   \n","\n","                               function  \\\n","seq                                       \n","1       pyspark.sql.DataFrameReader.csv   \n","2       pyspark.sql.DataFrameReader.csv   \n","3       pyspark.sql.DataFrameReader.csv   \n","4       pyspark.sql.DataFrameReader.csv   \n","5    pyspark.sql.DataFrameReader.format   \n","\n","                                        example_text_1  \\\n","seq                                                      \n","1    # Write a DataFrame into a CSV file<br>...    ...   \n","2    # Write a DataFrame into a CSV file<br>...    ...   \n","3    # Read the CSV file as a DataFrame with 'nullV...   \n","4    # Read the CSV file as a DataFrame with 'nullV...   \n","5    # Write a DataFrame into a JSON file<br>...   ...   \n","\n","                                      code_description  \\\n","seq                                                      \n","1    Pyspark code to  Write a DataFrame into a CSV ...   \n","2    Pyspark code which Loads a CSV file and return...   \n","3    Pyspark code to  Read the CSV file as a DataFr...   \n","4    Pyspark code which Loads a CSV file and return...   \n","5    Pyspark code to  Write a DataFrame into a JSON...   \n","\n","                                          code_snippet import_line  \n","seq                                                                 \n","1    df.write.mode(\"overwrite\").format(\"csv\").save(...              \n","2    df.write.mode(\"overwrite\").format(\"csv\").save(...              \n","3    df = spark.read.csv(my_dir, schema=df.schema, ...              \n","4    df = spark.read.csv(my_dir, schema=df.schema, ...              \n","5    df.write.mode(\"overwrite\").format(\"json\").save...              "],"text/html":["\n","  <div id=\"df-17daf704-5f11-4ba5-a81c-0c13ca4c8738\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature_desc</th>\n","      <th>example_text</th>\n","      <th>Category</th>\n","      <th>function</th>\n","      <th>example_text_1</th>\n","      <th>code_description</th>\n","      <th>code_snippet</th>\n","      <th>import_line</th>\n","    </tr>\n","    <tr>\n","      <th>seq</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Loads a CSV file and returns the result as a  ...</td>\n","      <td># Write a DataFrame into a CSV file and read i...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","      <td># Write a DataFrame into a CSV file&lt;br&gt;...    ...</td>\n","      <td>Pyspark code to  Write a DataFrame into a CSV ...</td>\n","      <td>df.write.mode(\"overwrite\").format(\"csv\").save(...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Loads a CSV file and returns the result as a  ...</td>\n","      <td># Write a DataFrame into a CSV file and read i...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","      <td># Write a DataFrame into a CSV file&lt;br&gt;...    ...</td>\n","      <td>Pyspark code which Loads a CSV file and return...</td>\n","      <td>df.write.mode(\"overwrite\").format(\"csv\").save(...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Loads a CSV file and returns the result as a  ...</td>\n","      <td># Write a DataFrame into a CSV file and read i...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","      <td># Read the CSV file as a DataFrame with 'nullV...</td>\n","      <td>Pyspark code to  Read the CSV file as a DataFr...</td>\n","      <td>df = spark.read.csv(my_dir, schema=df.schema, ...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Loads a CSV file and returns the result as a  ...</td>\n","      <td># Write a DataFrame into a CSV file and read i...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","      <td># Read the CSV file as a DataFrame with 'nullV...</td>\n","      <td>Pyspark code which Loads a CSV file and return...</td>\n","      <td>df = spark.read.csv(my_dir, schema=df.schema, ...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Specifies the input data source format.</td>\n","      <td>spark.read.format('json')&lt;br&gt;# Write a DataFra...</td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.format</td>\n","      <td># Write a DataFrame into a JSON file&lt;br&gt;...   ...</td>\n","      <td>Pyspark code to  Write a DataFrame into a JSON...</td>\n","      <td>df.write.mode(\"overwrite\").format(\"json\").save...</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17daf704-5f11-4ba5-a81c-0c13ca4c8738')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-17daf704-5f11-4ba5-a81c-0c13ca4c8738 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-17daf704-5f11-4ba5-a81c-0c13ca4c8738');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-994a5be8-f63e-4f2f-81ee-5f80d10cc7fd\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-994a5be8-f63e-4f2f-81ee-5f80d10cc7fd')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-994a5be8-f63e-4f2f-81ee-5f80d10cc7fd button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_input_output","repr_error":"'str' object has no attribute 'empty'"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# VERIFY/MASSAGE FUNCTION CATEGORIES - PASS 1:\n","\n","df_functions_1 = df_final_pass[df_final_pass['Category'].isin([\n","  'DataFrame'\n","  'Normal Functions',\n","  'Math Functions',\n","  'Datetime Functions',\n","  'Collection Functions',\n","  'Partition Transformation Functions',\n","  'Aggregate Functions',\n","  'Window Functions',\n","  'Sort Functions',\n","  'String Functions',\n","  'Bitwise Functions',\n","  'Misc Functions',\n","  'Predicate Functions',\n","  'Xml Functions',\n","  'Grouping'\n","  # -- IGNORED --'Call Functions',\n","  # -- IGNORED -- 'Window',\n","])].copy().set_index('seq')\n","\n","# Function for FUNCTIONS to massage the code_text in order to separate the comments and the corresponding code. It will be use to separate them into two different columns\n","def fn_functions_cleanse(code_text, function, comment, flag):\n","  result = ''\n","  result_com = ''\n","  import_fn='--dummy--'\n","  append_import_ln = 'N'\n","\n","  function_main = function.split('.')[-1:][0].strip()\n","\n","  # Special handling\n","  if function_main == 'ceiling':\n","    function_main = 'ceil'\n","  if function_main == 'negate':\n","    function_main = 'negative'\n","\n","  function_main = function_main + '('\n","\n","  if type(comment) == str:\n","    comment = 'Pyspark code which ' + '.'.join(comment.split('.')[:2])  # Keep only first two lines of feature_desc\n","\n","  if flag != 'COMMENT':\n","      code_text = code_text.replace('<br>... ', '')\n","      code_text = re.sub(r\"spark\\.createDataFrame\\(\\[\\(.*?\\)\\],\\s*\\[.*?\\]\\)\", 'df', code_text)\n","      code_text = re.sub(r\"spark\\.createDataFrame\\(\\s*\\[\\(.*?\\)\\],\\s*\\[.*?\\]\\)\", 'df', code_text)\n","      code_text = re.sub(r\"spark\\.createDataFrame\\(\\s*\\[\\[\\(.*?\\)\\]\\]\\)\", 'df', code_text)\n","      code_text = re.sub(r\"spark\\.range\\([A-Za-z0-9 ]+\\)\\.\", 'df.', code_text)\n","      code_text = re.sub(r\"spark\\.range\\([^)]*\\)\\.\", 'df.', code_text)\n","      code_text = code_text.replace('cDf', 'df')\n","      code_text = code_text.replace('df.show()', '')\n","      code_text = code_text.replace('.show()', '')\n","      code_text = code_text.replace('w.select', 'df.select')\n","      code_text = code_text.replace('w.win', 'df.win')\n","      code_text = code_text.replace('rodf.', 'df.')\n","      code_text = code_text.replace('time_df.', 'df.')\n","      code_text = code_text.replace('w = ', '')\n","      code_text = code_text.replace('prods =', '')\n","      code_text = code_text.replace('... #', '#')\n","      code_text = re.sub(r\"spark\\.createDataFrame\\(\\s*\\[\\[\\(.*?\\)\\]\\]\\)\", 'df', code_text)\n","\n","  for index, line in enumerate(code_text.split('<br>')):\n","\n","    if 'import ' in line:\n","      import_fn = line.strip().split(' ')[-1:][0].strip() + '.'\n","      import_ln = line.strip()\n","\n","    if len(line) != 0:\n","\n","      if flag == 'COMMENT' and line.startswith('#') and line.strip() != '':\n","        #print(f'--DEBUG--  function_main:{function_main} comment:{comment}')\n","        if line.startswith('#'):\n","          result_com = result_com + line.replace('#', 'Pyspark code which ')\n","          result_com = re.sub(r'Example \\d+:', '', result_com)\n","\n","      if flag != 'COMMENT' and not line.startswith('#')\\\n","        and function_main in line and 'df = spark.range' not in line:\n","\n","        #print(f'--DEBUG--  function_main:{function_main} import_fn:{import_fn} line:{line}')\n","        if import_fn in line:\n","          append_import_ln = 'Y'\n","\n","        if function in ['pyspark.sql.functions.col', 'pyspark.sql.functions.column']:\n","          line = f'df.select({line})'\n","\n","        result = result + line\n","        result = result.replace('df \\ .', 'df.')\n","        result = result + '<br>'\n","\n","  if flag == 'COMMENT':\n","    if result_com.strip() == '':\n","      result = [comment]\n","    else:\n","      result = [comment, result_com]\n","  else:\n","    #print(result)\n","    result = result.replace('spark.createDataFrame(    [[1], [1], [2]], [\"c\"])', 'df')\n","\n","    if append_import_ln == 'Y':\n","      result = import_ln + '<br>' + result\n","  return result\n","\n","# Drop some complicated code_snippets\n","fn_display_message(f' --> Display Initial count: {df_functions_1.shape[0]}')\n","df_functions_1 = df_functions_1[~df_functions_1['function'].isin(\n","    [\n","        'pyspark.sql.Column', 'pyspark.sql.functions.some', 'pyspark.sql.functions.every'\n","    ])]\n","fn_display_message(f' --> Display Count After dropping some complicated code_snippet: {df_functions_1.shape[0]}')\n","\n","# Split code text based on comments\n","df_functions_1['example_text_1'] = df_functions_1['example_text'].apply(lambda x: fn_split_comments(x, 'N'))\n","\n","# Normalize the code based on the elements in the array derived for example_text_1\n","fn_display_message(f' --> Display Count Before Explode on comments initial split on # : {df_functions_1.shape[0]}')\n","df_functions_1 = df_functions_1.explode('example_text_1')\n","df_functions_1['seq'] = range(1, len(df_functions_1) + 1)\n","df_functions_1 = df_functions_1.set_index('seq')\n","fn_display_message(f' --> Display Count After Explode on comments inital split on # : {df_functions_1.shape[0]}')\n","\n","# Derive code_snippet and code_description\n","df_functions_1['code_description'] = df_functions_1[['example_text', 'function', 'feature_desc']].apply(lambda x: fn_functions_cleanse(x['example_text'],  x['function'], x['feature_desc'], 'COMMENT'), axis=1)\n","df_functions_1['code_snippet'] = df_functions_1[['example_text', 'function', 'feature_desc']].apply(lambda x: fn_functions_cleanse(x['example_text'],  x['function'], x['feature_desc'], 'CODE'), axis=1)\n","\n","# Normalize the code based on the elements in the array derived for code_description\n","df_functions_1 = df_functions_1.explode('code_description')\n","df_functions_1['seq'] = range(1, len(df_functions_1) + 1)\n","df_functions_1 = df_functions_1.set_index('seq')\n","fn_display_message(f' --> Display Count After Explode on comments: {df_functions_1.shape[0]}')\n","\n","# Move the import statements into another column\n","df_functions_1['import_line'] = df_functions_1[\"code_snippet\"].apply(lambda x: x.split(\"<br>\")[0] if \"import\" in x else \"\")\n","df_functions_1['code_snippet'] = df_functions_1[\"code_snippet\"].apply(lambda x: '<br>'.join(x.split(\"<br>\")[1:]) if \"import\" in x else x)\n","\n","# Drop Duplicates before explode on Newline\n","df_functions_1 = df_functions_1.drop_duplicates()\n","fn_display_message(f' --> Display Count After dropping duplicates - 1: {df_functions_1.shape[0]}')\n","\n","# Explode on Newline <br>, drop Nulls and blanks\n","df_functions_1[\"code_snippet\"] = df_functions_1[\"code_snippet\"].str.split(\"<br>\")\n","df_functions_1 = df_functions_1.explode(\"code_snippet\").dropna().query(\"code_snippet != ''\")\n","df_functions_1['seq'] = range(1, len(df_functions_1) + 1)\n","df_functions_1 = df_functions_1.set_index('seq')\n","fn_display_message(f' --> Display Count After Explode on newline <br>: {df_functions_1.shape[0]}')\n","\n","# Drop Duplicates before explode on Newline\n","df_functions_1 = df_functions_1.drop_duplicates()\n","fn_display_message(f' --> Display Count After dropping duplicates - 2: {df_functions_1.shape[0]}')\n","\n","#df_functions_1 = df_functions_1[['code_description', 'code_snippet', 'import_line', 'example_text_1', 'function']] #, 'example_text', 'feature_desc', 'Category', 'function']]\n","df_functions_1.head()#.style.set_properties(**{'text-align': 'left'})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":463},"id":"ugv-WLNEUsz3","executionInfo":{"status":"ok","timestamp":1709782101941,"user_tz":-330,"elapsed":500,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"85808f9f-82cd-4af3-9a93-5fba38c21325"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" --> Display Initial count: 429\n"," --> Display Count After dropping some complicated code_snippet: 398\n"," --> Display Count Before Explode on comments initial split on # : 398\n"," --> Display Count After Explode on comments inital split on # : 437\n"," --> Display Count After Explode on comments: 493\n"," --> Display Count After dropping duplicates - 1: 491\n"," --> Display Count After Explode on newline <br>: 756\n"," --> Display Count After dropping duplicates - 2: 745\n"]},{"output_type":"execute_result","data":{"text/plain":["                                          feature_desc  \\\n","seq                                                      \n","1    Computes the square root of the specified floa...   \n","2                         Computes the absolute value.   \n","3         Computes inverse cosine of the input column.   \n","4    Computes inverse hyperbolic cosine of the inpu...   \n","5           Computes inverse sine of the input column.   \n","\n","                                          example_text        Category  \\\n","seq                                                                      \n","1    df = spark.range(1)<br>df.select(sqrt(lit(4)))...  Math Functions   \n","2    df = spark.range(1)<br>df.select(abs(lit(-1)))...  Math Functions   \n","3    df = spark.range(1, 3)<br>df.select(acos(df.id...  Math Functions   \n","4    df = spark.range(2)<br>df.select(acosh(col(\"id...  Math Functions   \n","5    df = spark.createDataFrame([(0,), (2,)])<br>df...  Math Functions   \n","\n","                        function  \\\n","seq                                \n","1     pyspark.sql.functions.sqrt   \n","2      pyspark.sql.functions.abs   \n","3     pyspark.sql.functions.acos   \n","4    pyspark.sql.functions.acosh   \n","5     pyspark.sql.functions.asin   \n","\n","                                        example_text_1  \\\n","seq                                                      \n","1    df = spark.range(1)<br>df.select(sqrt(lit(4)))...   \n","2    df = spark.range(1)<br>df.select(abs(lit(-1)))...   \n","3    df = spark.range(1, 3)<br>df.select(acos(df.id...   \n","4    df = spark.range(2)<br>df.select(acosh(col(\"id...   \n","5    df = spark.createDataFrame([(0,), (2,)])<br>df...   \n","\n","                                      code_description  \\\n","seq                                                      \n","1    Pyspark code which Computes the square root of...   \n","2      Pyspark code which Computes the absolute value.   \n","3    Pyspark code which Computes inverse cosine of ...   \n","4    Pyspark code which Computes inverse hyperbolic...   \n","5    Pyspark code which Computes inverse sine of th...   \n","\n","                                   code_snippet import_line  \n","seq                                                          \n","1                       df.select(sqrt(lit(4)))              \n","2                       df.select(abs(lit(-1)))              \n","3                        df.select(acos(df.id))              \n","4                   df.select(acosh(col(\"id\")))              \n","5    df.select(asin(df.schema.fieldNames()[0]))              "],"text/html":["\n","  <div id=\"df-8db35a67-006f-4818-8e65-8aafded18207\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature_desc</th>\n","      <th>example_text</th>\n","      <th>Category</th>\n","      <th>function</th>\n","      <th>example_text_1</th>\n","      <th>code_description</th>\n","      <th>code_snippet</th>\n","      <th>import_line</th>\n","    </tr>\n","    <tr>\n","      <th>seq</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Computes the square root of the specified floa...</td>\n","      <td>df = spark.range(1)&lt;br&gt;df.select(sqrt(lit(4)))...</td>\n","      <td>Math Functions</td>\n","      <td>pyspark.sql.functions.sqrt</td>\n","      <td>df = spark.range(1)&lt;br&gt;df.select(sqrt(lit(4)))...</td>\n","      <td>Pyspark code which Computes the square root of...</td>\n","      <td>df.select(sqrt(lit(4)))</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Computes the absolute value.</td>\n","      <td>df = spark.range(1)&lt;br&gt;df.select(abs(lit(-1)))...</td>\n","      <td>Math Functions</td>\n","      <td>pyspark.sql.functions.abs</td>\n","      <td>df = spark.range(1)&lt;br&gt;df.select(abs(lit(-1)))...</td>\n","      <td>Pyspark code which Computes the absolute value.</td>\n","      <td>df.select(abs(lit(-1)))</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Computes inverse cosine of the input column.</td>\n","      <td>df = spark.range(1, 3)&lt;br&gt;df.select(acos(df.id...</td>\n","      <td>Math Functions</td>\n","      <td>pyspark.sql.functions.acos</td>\n","      <td>df = spark.range(1, 3)&lt;br&gt;df.select(acos(df.id...</td>\n","      <td>Pyspark code which Computes inverse cosine of ...</td>\n","      <td>df.select(acos(df.id))</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Computes inverse hyperbolic cosine of the inpu...</td>\n","      <td>df = spark.range(2)&lt;br&gt;df.select(acosh(col(\"id...</td>\n","      <td>Math Functions</td>\n","      <td>pyspark.sql.functions.acosh</td>\n","      <td>df = spark.range(2)&lt;br&gt;df.select(acosh(col(\"id...</td>\n","      <td>Pyspark code which Computes inverse hyperbolic...</td>\n","      <td>df.select(acosh(col(\"id\")))</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Computes inverse sine of the input column.</td>\n","      <td>df = spark.createDataFrame([(0,), (2,)])&lt;br&gt;df...</td>\n","      <td>Math Functions</td>\n","      <td>pyspark.sql.functions.asin</td>\n","      <td>df = spark.createDataFrame([(0,), (2,)])&lt;br&gt;df...</td>\n","      <td>Pyspark code which Computes inverse sine of th...</td>\n","      <td>df.select(asin(df.schema.fieldNames()[0]))</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8db35a67-006f-4818-8e65-8aafded18207')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8db35a67-006f-4818-8e65-8aafded18207 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8db35a67-006f-4818-8e65-8aafded18207');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a6f7a61e-7429-4d56-ad02-6a67449562ee\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6f7a61e-7429-4d56-ad02-6a67449562ee')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a6f7a61e-7429-4d56-ad02-6a67449562ee button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_functions_1","summary":"{\n  \"name\": \"df_functions_1\",\n  \"rows\": 745,\n  \"fields\": [\n    {\n      \"column\": \"feature_desc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 368,\n        \"samples\": [\n          \"Generate a sequence of integers from start to stop  incrementing by step.If step is not set  incrementing by 1 if start is less than or equal to stop otherwise  1.\",\n          \"Returns the value of the first argument raised to the power of the second argument.\",\n          \"Computes cosecant of the input column.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"example_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 395,\n        \"samples\": [\n          \"df = spark.createDataFrame([('2015-04-08',)], ['dt'])<br>df.select(dayofyear('dt').alias('day')).collect()<br>\",\n          \"df = spark.createDataFrame([(None,), (1,)], [\\\"e\\\"])<br>df.select(isnotnull(df.e).alias('r')).collect()<br>\",\n          \"df = spark.range(10)<br>df.select(sum(df[\\\"id\\\"])).show()<br>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Xml Functions\",\n          \"Misc Functions\",\n          \"Math Functions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"function\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 396,\n        \"samples\": [\n          \"pyspark.sql.functions.dayofweek\",\n          \"pyspark.sql.functions.contains\",\n          \"pyspark.sql.functions.sum_distinct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"example_text_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 425,\n        \"samples\": [\n          \"# Calculate the min of the age and height in all data.<br>df.groupBy().min(\\\"age\\\", \\\"height\\\").show()<br><br><br>\",\n          \"df = spark.createDataFrame([('2015-04-08',)], ['dt'])<br>df.select(day('dt').alias('day')).collect()<br><br>\",\n          \"df = spark.createDataFrame([([1, 20, 3, 5],), ([1, 20, None, 3],)], ['data'])<br>df.select(shuffle(df.data).alias('s')).collect()<br><br>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 385,\n        \"samples\": [\n          \"Pyspark code which Computes the first argument into a string from a binary using the provided character set one of    US ASCII        ISO 8859 1        UTF 8        UTF 16BE        UTF 16LE        UTF 16    .\",\n          \"Pyspark code which Window function  returns the rank of rows within a window partition. The difference between rank and dense rank is that dense rank leaves no gaps in rankingsequence when there are ties\",\n          \"Pyspark code which Returns null if col1 equals to col2  or col1 otherwise.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code_snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 567,\n        \"samples\": [\n          \"df.select(xpath_int(df.x, lit('sum(a/b)')).alias('r')).collect()\",\n          \"df.select(try_aes_decrypt(unbase64(df.input), df.key, df.mode).alias('r')).collect()\",\n          \"df.select(from_json(df.value, schema).alias(\\\"json\\\")).collect()\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"import_line\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"import pyspark.sql.functions as sf\",\n          \"from pyspark.sql.streaming.state import GroupStateTimeout\",\n          \"import math\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":[],"metadata":{"id":"xZqEsHyPOeDe"}},{"cell_type":"code","source":["# CONCATENATE RELEVANT DATAFRAMES TO FORM FINAL DATASET\n","\n","final_columns = ['code_description', 'code_snippet', 'import_line', 'Category', 'function']\n","\n","df_final = pd.concat([\n","    df_input_output[final_columns],\n","    df_functions_1[final_columns]\n","    ], ignore_index=True)\n","\n","\n","# Drop Duplicates and NULL code_snippet or code_description\n","fn_display_message(f' --> Display Count Before deleting records: {df_final.shape[0]}')\n","df_final = df_final.drop_duplicates()\n","fn_display_message(f' --> Display Count After dropping duplicates: {df_final.shape[0]}')\n","\n","df_final = df_final.explode(\"code_snippet\").dropna().query(\"code_snippet != ''\")\n","fn_display_message(f' --> Display Count After dropping NULL code_snippet: {df_final.shape[0]}')\n","\n","df_final = df_final.explode(\"code_description\").dropna().query(\"code_description != ''\")\n","fn_display_message(f' --> Display Count After dropping NULL code_description: {df_final.shape[0]}')\n","\n","\n","\n","df_final#.style.set_properties(**{'text-align': 'left'})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":493},"id":"NhGU3kHVEPiC","executionInfo":{"status":"ok","timestamp":1709782101942,"user_tz":-330,"elapsed":29,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"ad579d04-2528-4836-9c94-53e62fe1b4f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" --> Display Count Before deleting records: 835\n"," --> Display Count After dropping duplicates: 694\n"," --> Display Count After dropping NULL code_snippet: 694\n"," --> Display Count After dropping NULL code_description: 694\n"]},{"output_type":"execute_result","data":{"text/plain":["                                      code_description  \\\n","0    Pyspark code to  Write a DataFrame into a CSV ...   \n","1    Pyspark code which Loads a CSV file and return...   \n","2    Pyspark code to  Read the CSV file as a DataFr...   \n","3    Pyspark code which Loads a CSV file and return...   \n","4    Pyspark code to  Write a DataFrame into a JSON...   \n","..                                                 ...   \n","818  Pyspark code which  Group-by name, and calcula...   \n","827  Pyspark code which Applies a function to each ...   \n","828  Pyspark code which Applies a function to each ...   \n","829  Pyspark code which  Alternatively, the user ca...   \n","830  Pyspark code which  Alternatively, the user ca...   \n","\n","                                          code_snippet import_line  \\\n","0    df.write.mode(\"overwrite\").format(\"csv\").save(...               \n","1    df.write.mode(\"overwrite\").format(\"csv\").save(...               \n","2    df = spark.read.csv(my_dir, schema=df.schema, ...               \n","3    df = spark.read.csv(my_dir, schema=df.schema, ...               \n","4    df.write.mode(\"overwrite\").format(\"json\").save...               \n","..                                                 ...         ...   \n","818                  df.groupBy().sum(\"age\", \"height\")               \n","827  df1.groupby(\"id\").cogroup(df2.groupby(\"id\")).a...               \n","828  df1.groupby(\"id\").cogroup(df2.groupby(\"id\")).a...               \n","829  df1.groupby(\"id\").cogroup(df2.groupby(\"id\")).a...               \n","830  df1.groupby(\"id\").cogroup(df2.groupby(\"id\")).a...               \n","\n","         Category                                      function  \n","0    Input/Output               pyspark.sql.DataFrameReader.csv  \n","1    Input/Output               pyspark.sql.DataFrameReader.csv  \n","2    Input/Output               pyspark.sql.DataFrameReader.csv  \n","3    Input/Output               pyspark.sql.DataFrameReader.csv  \n","4    Input/Output            pyspark.sql.DataFrameReader.format  \n","..            ...                                           ...  \n","818      Grouping                   pyspark.sql.GroupedData.sum  \n","827      Grouping  pyspark.sql.PandasCogroupedOps.applyInPandas  \n","828      Grouping  pyspark.sql.PandasCogroupedOps.applyInPandas  \n","829      Grouping  pyspark.sql.PandasCogroupedOps.applyInPandas  \n","830      Grouping  pyspark.sql.PandasCogroupedOps.applyInPandas  \n","\n","[694 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-7eec8c2f-bc9f-433f-b953-79cad40f6a5d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>code_description</th>\n","      <th>code_snippet</th>\n","      <th>import_line</th>\n","      <th>Category</th>\n","      <th>function</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Pyspark code to  Write a DataFrame into a CSV ...</td>\n","      <td>df.write.mode(\"overwrite\").format(\"csv\").save(...</td>\n","      <td></td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Pyspark code which Loads a CSV file and return...</td>\n","      <td>df.write.mode(\"overwrite\").format(\"csv\").save(...</td>\n","      <td></td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Pyspark code to  Read the CSV file as a DataFr...</td>\n","      <td>df = spark.read.csv(my_dir, schema=df.schema, ...</td>\n","      <td></td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Pyspark code which Loads a CSV file and return...</td>\n","      <td>df = spark.read.csv(my_dir, schema=df.schema, ...</td>\n","      <td></td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.csv</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Pyspark code to  Write a DataFrame into a JSON...</td>\n","      <td>df.write.mode(\"overwrite\").format(\"json\").save...</td>\n","      <td></td>\n","      <td>Input/Output</td>\n","      <td>pyspark.sql.DataFrameReader.format</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>818</th>\n","      <td>Pyspark code which  Group-by name, and calcula...</td>\n","      <td>df.groupBy().sum(\"age\", \"height\")</td>\n","      <td></td>\n","      <td>Grouping</td>\n","      <td>pyspark.sql.GroupedData.sum</td>\n","    </tr>\n","    <tr>\n","      <th>827</th>\n","      <td>Pyspark code which Applies a function to each ...</td>\n","      <td>df1.groupby(\"id\").cogroup(df2.groupby(\"id\")).a...</td>\n","      <td></td>\n","      <td>Grouping</td>\n","      <td>pyspark.sql.PandasCogroupedOps.applyInPandas</td>\n","    </tr>\n","    <tr>\n","      <th>828</th>\n","      <td>Pyspark code which Applies a function to each ...</td>\n","      <td>df1.groupby(\"id\").cogroup(df2.groupby(\"id\")).a...</td>\n","      <td></td>\n","      <td>Grouping</td>\n","      <td>pyspark.sql.PandasCogroupedOps.applyInPandas</td>\n","    </tr>\n","    <tr>\n","      <th>829</th>\n","      <td>Pyspark code which  Alternatively, the user ca...</td>\n","      <td>df1.groupby(\"id\").cogroup(df2.groupby(\"id\")).a...</td>\n","      <td></td>\n","      <td>Grouping</td>\n","      <td>pyspark.sql.PandasCogroupedOps.applyInPandas</td>\n","    </tr>\n","    <tr>\n","      <th>830</th>\n","      <td>Pyspark code which  Alternatively, the user ca...</td>\n","      <td>df1.groupby(\"id\").cogroup(df2.groupby(\"id\")).a...</td>\n","      <td></td>\n","      <td>Grouping</td>\n","      <td>pyspark.sql.PandasCogroupedOps.applyInPandas</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>694 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7eec8c2f-bc9f-433f-b953-79cad40f6a5d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7eec8c2f-bc9f-433f-b953-79cad40f6a5d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7eec8c2f-bc9f-433f-b953-79cad40f6a5d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-499185a2-96d3-4484-8d5d-ce19f085509e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-499185a2-96d3-4484-8d5d-ce19f085509e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-499185a2-96d3-4484-8d5d-ce19f085509e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_5ca09f65-f9a9-41f8-b9c7-3bd65d20ec9a\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_final')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_5ca09f65-f9a9-41f8-b9c7-3bd65d20ec9a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_final');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_final","summary":"{\n  \"name\": \"df_final\",\n  \"rows\": 694,\n  \"fields\": [\n    {\n      \"column\": \"code_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 427,\n        \"samples\": [\n          \"Pyspark code which Computes the min value for each numeric column for each group.\",\n          \"Pyspark code which Returns the positive value of dividend mod divisor.\",\n          \"Pyspark code which Returns whether a predicate holds for one or more elements in the array.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code_snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 603,\n        \"samples\": [\n          \"df.select(add_months(df.dt, 1).alias('next_month')).collect()\",\n          \"df.select(aes_decrypt(aes_encrypt(df.input, df.key, df.mode),    df.key, df.mode).alias('r')).collect()\",\n          \"df.select(sf.ifnull(df.e, sf.lit(8)))\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"import_line\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"import pyspark.sql.functions as sf\",\n          \"from pyspark.sql.streaming.state import GroupStateTimeout\",\n          \"import math\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"Bitwise Functions\",\n          \"Predicate Functions\",\n          \"Input/Output\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"function\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 417,\n        \"samples\": [\n          \"pyspark.sql.functions.array_append\",\n          \"pyspark.sql.functions.xpath\",\n          \"pyspark.sql.GroupedData.count\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# GET COUNT OF VARIOUS CATGEGORIES OF FUNCTIONS\n","\n","df_categories = df_final.groupby(\"Category\").size()\n","\n","df_categories"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nDCQ3-scVvt","executionInfo":{"status":"ok","timestamp":1709782101942,"user_tz":-330,"elapsed":25,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"1278a98f-a827-43a4-d2d0-d8e7ad68ea5b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Category\n","Aggregate Functions                    77\n","Bitwise Functions                       3\n","Collection Functions                  105\n","Datetime Functions                     99\n","Grouping                               42\n","Input/Output                           90\n","Math Functions                         78\n","Misc Functions                         50\n","Partition Transformation Functions      5\n","Predicate Functions                     6\n","Sort Functions                          8\n","String Functions                      108\n","Window Functions                       14\n","Xml Functions                           9\n","dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# WRITE FINAL DATASET TO CSV AND DOWNLOAD\n","\n","DOWNLOAD_FLAG = 'Y'\n","if DOWNLOAD_FLAG == 'Y':\n","  df_final.to_csv('ETL_P2_model_input_data_v1.csv')\n","\n","  from google.colab import files\n","  files.download('ETL_P2_model_input_data_v1.csv')"],"metadata":{"id":"jWYfCrGWsMwH","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1709782101942,"user_tz":-330,"elapsed":24,"user":{"displayName":"SK G","userId":"17874234191554613076"}},"outputId":"e9b4a2f7-83a8-4ebf-d33c-d9f4419061db"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a0e22feb-ebfc-494e-8a49-f53c4c0f2965\", \"ETL_P2_model_input_data_v1.csv\", 169267)"]},"metadata":{}}]}]}